"""
AI Analyzer for Pharma Daily
Uses DeepSeek API for intelligent news analysis and summarization.
"""

import os
import json
import logging
from typing import Optional
from datetime import datetime

from .fetcher import NewsItem
from .config import CATEGORIES

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# DeepSeek API configuration
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY", "")
DEEPSEEK_BASE_URL = "https://api.deepseek.com"
DEEPSEEK_MODEL = os.environ.get("DEEPSEEK_MODEL", "deepseek-chat")


class AIAnalyzer:
    """
    AI-powered pharmaceutical news analyzer using DeepSeek API.
    """

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or DEEPSEEK_API_KEY
        self.client = None

        if self.api_key:
            try:
                from openai import OpenAI
                self.client = OpenAI(
                    api_key=self.api_key,
                    base_url=DEEPSEEK_BASE_URL
                )
                logger.info("DeepSeek API client initialized")
            except ImportError:
                logger.warning("openai package not installed, AI analysis disabled")
        else:
            logger.warning("DEEPSEEK_API_KEY not set, AI analysis disabled")

    def analyze_news(self, items: list[NewsItem], date_str: str) -> dict:
        """
        Analyze news items using DeepSeek API.

        Args:
            items: List of NewsItem objects
            date_str: Date string for the analysis

        Returns:
            Dictionary containing analysis results
        """
        if not self.client or not items:
            return self._fallback_analysis(items, date_str)

        # Prepare news data for analysis
        news_text = self._format_news_for_prompt(items)

        prompt = f"""ä½ æ˜¯èµ„æ·±åˆ¶è¯è¡Œä¸šåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹æœ€è¿‘ä¸€å‘¨ï¼ˆæˆªè‡³ {date_str}ï¼‰çš„åˆ¶è¯è¡Œä¸šæ–°é—»ï¼Œå¹¶æŒ‰è¦æ±‚è¾“å‡ºã€‚

## æ–°é—»åˆ—è¡¨

{news_text}

## åˆ†æè¦æ±‚

è¯·è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{{
  "overview": "æœ¬å‘¨æ¦‚è§ˆï¼Œ2-3å¥è¯æ€»ç»“æœ€é‡è¦çš„è¡Œä¸šåŠ¨æ€",
  "top_news": [
    {{
      "index": 1,
      "title": "æ–°é—»æ ‡é¢˜",
      "importance": 5,
      "reason": "é‡è¦æ€§åŸå› ï¼ˆä¸€å¥è¯ï¼‰",
      "category": "ç±»åˆ«"
    }}
  ],
  "category_summary": {{
    "æ–°è¯ç ”å‘": "è¯¥ç±»åˆ«ç®€è¦æ€»ç»“",
    "ä¸´åºŠè¯•éªŒ": "è¯¥ç±»åˆ«ç®€è¦æ€»ç»“"
  }},
  "tomorrow_watch": "æ˜æ—¥å€¼å¾—å…³æ³¨çš„äº‹é¡¹"
}}
```

## åˆ†ç±»æ ‡å‡†
- æ–°è¯ç ”å‘ (Drug R&D): ç ”å‘ç®¡çº¿ã€å€™é€‰è¯ç‰©ã€é¶ç‚¹å‘ç°
- ä¸´åºŠè¯•éªŒ (Clinical Trials): I/II/IIIæœŸè¯•éªŒã€ç–—æ•ˆæ•°æ®
- ç›‘ç®¡å®¡æ‰¹ (Regulatory): FDA/EMA/NMPAæ‰¹å‡†
- å•†ä¸šåŠ¨æ€ (Business/M&A): æ”¶è´­ã€å¹¶è´­ã€èèµ„ã€åˆä½œ
- å¸‚åœºåˆ†æ (Market Analysis): é”€å”®æ•°æ®ã€å¸‚åœºé¢„æµ‹
- æ”¿ç­–æ³•è§„ (Policy): åŒ»ä¿æ”¿ç­–ã€é›†é‡‡ã€è¡Œä¸šè§„å®š

## é‡è¦æ€§è¯„åˆ† (1-5)
- 5åˆ†: é‡å¤§çªç ´ï¼ˆæ–°è¯è·æ‰¹ã€>10äº¿ç¾å…ƒæ”¶è´­ã€çªç ´æ€§ç–—æ³•ï¼‰
- 4åˆ†: é‡è¦åŠ¨æ€ï¼ˆå…³é”®IIIæœŸæ•°æ®ã€å¤§å‹åˆä½œï¼‰
- 3åˆ†: ä¸€èˆ¬è¡Œä¸šæ–°é—»
- 2åˆ†: æ¬¡è¦æ–°é—»
- 1åˆ†: è¾¹ç¼˜ç›¸å…³

è¯·é€‰å‡ºæœ€é‡è¦çš„5æ¡æ–°é—»æ”¾å…¥ top_newsã€‚åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        try:
            logger.info("Calling DeepSeek API for analysis...")
            response = self.client.chat.completions.create(
                model=DEEPSEEK_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸“ä¸šçš„åˆ¶è¯è¡Œä¸šåˆ†æå¸ˆï¼Œæ“…é•¿æ–°é—»åˆ†æå’Œè¶‹åŠ¿æ´å¯Ÿã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¾“å‡ºæ ¼å¼ä¸º JSONã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=2000
            )

            content = response.choices[0].message.content.strip()

            # Extract JSON from response
            analysis = self._parse_json_response(content)

            if analysis:
                logger.info("AI analysis completed successfully")
                return analysis
            else:
                logger.warning("Failed to parse AI response, using fallback")
                return self._fallback_analysis(items, date_str)

        except Exception as e:
            logger.error(f"DeepSeek API error: {e}")
            return self._fallback_analysis(items, date_str)

    def _format_news_for_prompt(self, items: list[NewsItem]) -> str:
        """Format news items for the analysis prompt."""
        lines = []
        for i, item in enumerate(items[:30], 1):  # Limit to 30 items
            lang = "ä¸­æ–‡" if item.language == "zh" else "è‹±æ–‡"
            lines.append(f"{i}. [{item.source}] ({lang}) {item.title}")
            if item.summary:
                summary = item.summary[:200] + "..." if len(item.summary) > 200 else item.summary
                lines.append(f"   æ‘˜è¦: {summary}")
            lines.append("")
        return "\n".join(lines)

    def _parse_json_response(self, content: str) -> Optional[dict]:
        """Parse JSON from AI response."""
        try:
            # Try direct parse
            return json.loads(content)
        except json.JSONDecodeError:
            pass

        # Try to extract JSON from markdown code block
        import re
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass

        # Try to find JSON object
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                return json.loads(json_match.group(0))
            except json.JSONDecodeError:
                pass

        return None

    def _fallback_analysis(self, items: list[NewsItem], date_str: str) -> dict:
        """Generate basic analysis without AI."""
        logger.info("Using fallback analysis (no AI)")

        # Sort by importance
        sorted_items = sorted(items, key=lambda x: x.importance, reverse=True)

        # Group by category
        categories = {}
        for item in items:
            cat = item.category or "ç»¼åˆ"
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(item)

        # Generate top news
        top_news = []
        for i, item in enumerate(sorted_items[:5], 1):
            top_news.append({
                "index": i,
                "title": item.title,
                "importance": item.importance or 3,
                "reason": f"æ¥è‡ª {item.source}",
                "category": item.category or "ç»¼åˆ"
            })

        # Generate category summary
        category_summary = {}
        for cat, cat_items in categories.items():
            category_summary[cat] = f"å…± {len(cat_items)} æ¡æ–°é—»"

        return {
            "overview": f"{date_str} å…±è·å– {len(items)} æ¡åˆ¶è¯è¡Œä¸šæ–°é—»ï¼Œæ¶µç›– {len(categories)} ä¸ªç±»åˆ«ã€‚",
            "top_news": top_news,
            "category_summary": category_summary,
            "tomorrow_watch": "è¯·å…³æ³¨å„ç±»ä¸´åºŠè¯•éªŒæ•°æ®æ›´æ–°å’Œç›‘ç®¡å®¡æ‰¹è¿›å±•ã€‚"
        }

    def format_analysis_markdown(self, analysis: dict, items: list[NewsItem]) -> str:
        """Format analysis results as Markdown."""
        lines = [
            "## ğŸ“Š AI æ™ºèƒ½åˆ†æ",
            "",
            "### æœ¬å‘¨æ¦‚è§ˆ",
            "",
            analysis.get("overview", ""),
            "",
            "### ğŸ”¥ é‡ç‚¹æ–°é—»",
            ""
        ]

        # Top news
        for news in analysis.get("top_news", []):
            stars = "â­" * news.get("importance", 3)
            lines.append(f"**{news['index']}. {news['title']}** {stars}")
            lines.append(f"   - ç±»åˆ«: {news.get('category', 'ç»¼åˆ')}")
            lines.append(f"   - {news.get('reason', '')}")
            lines.append("")

        # Category summary
        lines.extend([
            "### ğŸ“ åˆ†ç±»æ‘˜è¦",
            ""
        ])
        for cat, summary in analysis.get("category_summary", {}).items():
            en_name = CATEGORIES.get(cat, {}).get("en", "")
            lines.append(f"**{cat}** ({en_name}): {summary}")
        lines.append("")

        # Tomorrow watch
        if analysis.get("tomorrow_watch"):
            lines.extend([
                "### ğŸ”® æ˜æ—¥å…³æ³¨",
                "",
                analysis["tomorrow_watch"],
                ""
            ])

        return "\n".join(lines)


def analyze_with_ai(items: list[NewsItem], date_str: str, api_key: Optional[str] = None) -> tuple[dict, str]:
    """
    Convenience function to analyze news with AI.

    Args:
        items: List of NewsItem objects
        date_str: Date string
        api_key: Optional DeepSeek API key

    Returns:
        Tuple of (analysis dict, formatted markdown)
    """
    analyzer = AIAnalyzer(api_key)
    analysis = analyzer.analyze_news(items, date_str)
    markdown = analyzer.format_analysis_markdown(analysis, items)
    return analysis, markdown


if __name__ == "__main__":
    # Test with mock data
    from datetime import datetime

    mock_items = [
        NewsItem(
            title="FDAæ‰¹å‡†é¦–ä¸ªåŸºå› ç¼–è¾‘ç–—æ³•ç”¨äºé•°çŠ¶ç»†èƒç—…",
            link="https://example.com/1",
            summary="ç¾å›½FDAæ­£å¼æ‰¹å‡†äº†é¦–ä¸ªåŸºäºCRISPRæŠ€æœ¯çš„åŸºå› ç¼–è¾‘ç–—æ³•ã€‚",
            published=datetime.now(),
            source="FiercePharma",
            language="en",
            category="ç›‘ç®¡å®¡æ‰¹",
            importance=5
        ),
        NewsItem(
            title="è¾‰ç‘å®£å¸ƒä»¥430äº¿ç¾å…ƒæ”¶è´­Seagen",
            link="https://example.com/2",
            summary="è¾‰ç‘ä»Šæ—¥å®£å¸ƒå®Œæˆå¯¹Seagençš„æ”¶è´­ã€‚",
            published=datetime.now(),
            source="è¯æ˜åº·å¾·",
            language="zh",
            category="å•†ä¸šåŠ¨æ€",
            importance=5
        ),
    ]

    analyzer = AIAnalyzer()
    result = analyzer.analyze_news(mock_items, "2024-01-15")
    print(json.dumps(result, ensure_ascii=False, indent=2))
